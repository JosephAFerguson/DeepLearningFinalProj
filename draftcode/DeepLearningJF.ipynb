{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosephAFerguson/DeepLearningFinalProj/blob/main/DeepLearningJF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, time, os\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from requests import Session\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "YwvFxCVlJKZG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 1. CoinMarketCap API Helper\n",
        "# ----------------------------\n",
        "class CryptoEndpoint:\n",
        "    listingsEndpoint = \"https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest\"\n",
        "    latestQuotes = \"https://pro-api.coinmarketcap.com/v2/cryptocurrency/quotes/latest\"\n",
        "    historicalQuotes = \"https://pro-api.coinmarketcap.com/v2/cryptocurrency/quotes/historical\"\n",
        "\n",
        "    def __init__(self, apikey) -> None:\n",
        "        self.headers = {\n",
        "            'Accepts': 'application/json',\n",
        "            'X-CMC_PRO_API_KEY': apikey,\n",
        "        }\n",
        "        self.coinsInfo = {}\n",
        "        self.coinsIds = []\n",
        "\n",
        "    def GetCoinIdentifiers(self, limit=10):\n",
        "        session = Session()\n",
        "        session.headers.update(self.headers)\n",
        "        response = session.get(\n",
        "            url=self.listingsEndpoint,\n",
        "            params={\"limit\": limit, \"price_min\": 1, \"price_max\": 20}\n",
        "        )\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            raise Exception(f\"Error fetching listings: {response.text}\")\n",
        "\n",
        "        data = json.loads(response.text)\n",
        "\n",
        "        for coin in data.get(\"data\", []):\n",
        "            self.coinsInfo[coin[\"name\"]] = coin[\"id\"]\n",
        "            self.coinsIds.append(coin[\"id\"])\n",
        "\n",
        "        print(f\"Loaded {len(self.coinsInfo)} coins.\")\n",
        "        return (self.coinsInfo, self.coinsIds)\n",
        "\n",
        "    def GetSampleCoinHistoricalData(self, coin_id, days=60):\n",
        "        \"\"\"Fetch historical daily prices for one coin.\"\"\"\n",
        "        session = Session()\n",
        "        session.headers.update(self.headers)\n",
        "\n",
        "        end_time = datetime.utcnow()\n",
        "        start_time = end_time - timedelta(days=days)\n",
        "\n",
        "        params = {\n",
        "            \"id\": coin_id,\n",
        "            \"time_start\": start_time.isoformat(),\n",
        "            \"time_end\": end_time.isoformat(),\n",
        "            \"interval\": \"24h\",\n",
        "        }\n",
        "\n",
        "        response = session.get(url=self.historicalQuotes, params=params)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Error for coin {coin_id}: {response.text}\")\n",
        "            return []\n",
        "\n",
        "        data = json.loads(response.text)\n",
        "        if data.get(\"status\", {}).get(\"error_code\") != 0:\n",
        "            print(f\"API error for {coin_id}: {data['status']}\")\n",
        "            return []\n",
        "\n",
        "        coin_data = data.get(\"data\", {})\n",
        "        quotes = coin_data.get(\"quotes\", [])\n",
        "        if not quotes:\n",
        "            return []\n",
        "\n",
        "        historicals = []\n",
        "        for quote in quotes:\n",
        "            price = quote[\"quote\"][\"USD\"][\"price\"]\n",
        "            volume = quote[\"quote\"][\"USD\"][\"volume_24h\"]\n",
        "            marketcap = quote[\"quote\"][\"USD\"][\"market_cap\"]\n",
        "            circulating_supply = quote[\"quote\"][\"USD\"][\"circulating_supply\"]\n",
        "            total_supply = quote[\"quote\"][\"USD\"][\"total_supply\"]\n",
        "            historicals.append([price, volume, marketcap, circulating_supply, total_supply])\n",
        "\n",
        "        return historicals"
      ],
      "metadata": {
        "id": "nP90iGq4hMBO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim,\n",
        "                 bidirectional=True, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        self.final_hidden = hidden_dim * self.num_directions\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=layer_dim,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if layer_dim > 1 else 0.0,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        # --- Attention layers ---\n",
        "        self.attn = nn.Linear(self.final_hidden, self.final_hidden)\n",
        "        self.v = nn.Linear(self.final_hidden, 1, bias=False)\n",
        "\n",
        "        # Final classifier\n",
        "        self.fc = nn.Linear(self.final_hidden, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Initial hidden and cell states\n",
        "        h0 = torch.zeros(self.layer_dim * self.num_directions, batch_size, self.hidden_dim).to(x.device)\n",
        "        c0 = torch.zeros(self.layer_dim * self.num_directions, batch_size, self.hidden_dim).to(x.device)\n",
        "\n",
        "        # LSTM outputs: (batch, seq_len, hidden_dim * num_directions)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        # ---- Attention mechanism ----\n",
        "        # out → (batch, seq_len, hidden)\n",
        "        energy = torch.tanh(self.attn(out))                  # (batch, seq_len, hidden)\n",
        "        scores = self.v(energy).squeeze(-1)                  # (batch, seq_len)\n",
        "\n",
        "        attn_weights = F.softmax(scores, dim=1)              # (batch, seq_len)\n",
        "\n",
        "        # Weighted sum: context vector\n",
        "        context = torch.bmm(attn_weights.unsqueeze(1), out)  # (batch, 1, hidden)\n",
        "        context = context.squeeze(1)                         # (batch, hidden)\n",
        "\n",
        "        # Final prediction\n",
        "        return self.fc(context), attn_weights\n"
      ],
      "metadata": {
        "id": "EOb_EeFeiDck"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 3. Data Preparation Utility\n",
        "# ----------------------------\n",
        "def prepare_sequences(data_dict, window=10):\n",
        "    \"\"\"\n",
        "    Convert dict {coin_id: [[price, volume], ...]} into windowed tensors\n",
        "    Target: 1 if next price > current, else 0\n",
        "    \"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    X, Y, labels = [], [], []\n",
        "\n",
        "    for coin_id, seq in data_dict.items():\n",
        "        arr = np.array(seq)\n",
        "        if len(arr) <= window + 1:\n",
        "            continue\n",
        "        scaled = scaler.fit_transform(arr)\n",
        "        prices = arr[:, 0]\n",
        "\n",
        "        for i in range(len(scaled) - window - 1):\n",
        "            X.append(scaled[i:i+window])\n",
        "            next_dir = 1.0 if prices[i+window+1] > prices[i+window] else 0.0\n",
        "            Y.append(next_dir)\n",
        "            labels.append(coin_id)\n",
        "\n",
        "    X = torch.tensor(np.array(X), dtype=torch.float32)\n",
        "    Y = torch.tensor(np.array(Y), dtype=torch.float32).view(-1, 1)\n",
        "    return X, Y, labels"
      ],
      "metadata": {
        "id": "HXLRjxsJEcJa"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, trainX, trainY, valX, valY, epochs=200, lr=0.01, patience=20):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, patience=10, factor=0.2)\n",
        "\n",
        "    # Ensure tensors\n",
        "    trainX = torch.tensor(trainX, dtype=torch.float32)\n",
        "    trainY = torch.tensor(trainY, dtype=torch.float32)\n",
        "    valX   = torch.tensor(valX,   dtype=torch.float32)\n",
        "    valY   = torch.tensor(valY,   dtype=torch.float32)\n",
        "\n",
        "    noImprovment = 0\n",
        "    best_comb_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # ----------------------------\n",
        "        # Training\n",
        "        # ----------------------------\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs,attn = model(trainX)\n",
        "        loss = criterion(outputs, trainY)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # ----------------------------\n",
        "        # Validation\n",
        "        # ----------------------------\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs,valattn = model(valX)\n",
        "            val_loss = criterion(val_outputs, valY)\n",
        "\n",
        "            pred_train = torch.sigmoid(outputs)\n",
        "            train_acc = (pred_train.round() == trainY).float().mean().item()\n",
        "\n",
        "            pred_val = torch.sigmoid(val_outputs)\n",
        "            val_acc = (pred_val.round() == valY).float().mean().item()\n",
        "\n",
        "        # Step scheduler using validation loss\n",
        "        scheduler.step(val_loss)\n",
        "        if (train_acc+val_acc)/2 > best_comb_acc:\n",
        "          noImprovment = 0\n",
        "          best_comb_acc = (train_acc+val_acc)/2\n",
        "        elif noImprovment>patience:\n",
        "          return model\n",
        "        else:\n",
        "          noImprovment+=1\n",
        "\n",
        "        # Status print every epoch\n",
        "        print(\n",
        "            f\"Epoch [{epoch+1}/{epochs}] | \"\n",
        "            f\"Train Loss: {loss.item():.5f} | Train Acc: {train_acc*100:.2f}% | \"\n",
        "            f\"Val Loss: {val_loss.item():.5f} | Val Acc: {val_acc*100:.2f}%\"\n",
        "        )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "TF-YsBe6INRI"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 5. Get and Save Data as CSV\n",
        "# ----------------------------\n",
        "def GetSaveData():\n",
        "    apikey = input(\"Enter your CoinMarketCap API key: \").strip()\n",
        "    ce = CryptoEndpoint(apikey)\n",
        "\n",
        "    data_dir = \"data\"\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    # Optionally control how \"fresh\" the data should be before refetching\n",
        "    freshness_days = 1  # re-download if older than this many days\n",
        "\n",
        "    coinsInfo, coinsIds = ce.GetCoinIdentifiers(limit=10)\n",
        "    print(\"Fetching historical data (or loading cached files)...\")\n",
        "\n",
        "    all_data = {}\n",
        "\n",
        "    for coinId in coinsIds:\n",
        "        file_path = os.path.join(data_dir, f\"{coinId}.csv\")\n",
        "\n",
        "        # Check if we already have cached data\n",
        "        if os.path.exists(file_path):\n",
        "            modified_time = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
        "            if datetime.now() - modified_time < timedelta(days=freshness_days):\n",
        "                print(f\"[INFO] Using cached data for {coinId}\")\n",
        "                df = pd.read_csv(file_path)\n",
        "                all_data[coinId] = df\n",
        "                continue\n",
        "            else:\n",
        "                print(f\"[INFO] Cached data for {coinId} is old. Refetching...\")\n",
        "\n",
        "        # Fetch new data from API\n",
        "        hist = ce.GetSampleCoinHistoricalData(coinId, days=60)\n",
        "        if len(hist) > 0:\n",
        "            df = pd.DataFrame(hist)\n",
        "            df.to_csv(file_path, index=False)\n",
        "            print(f\"[INFO] Saved new data for {coinId} → {file_path}\")\n",
        "            all_data[coinId] = df\n",
        "        else:\n",
        "            print(f\"[WARN] No data found for {coinId}\")\n",
        "\n",
        "        time.sleep(2)  # Avoid hitting API rate limits\n",
        "\n",
        "    print(f\"\\n✅ Fetched or loaded data for {len(all_data)} coins.\")\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "L9Qu8SF2LAyy"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 6. Main Execution\n",
        "# ----------------------------\n",
        "all_data = GetSaveData()\n",
        "\n",
        "# Prepare sequences (X_all, Y_all, and matching labels)\n",
        "X_all, Y_all, labels = prepare_sequences(all_data, window=10)\n",
        "\n",
        "# Train / Val / Test split (60 / 20 / 20)\n",
        "trainX, restX, trainY, restY = train_test_split(\n",
        "    X_all, Y_all, test_size=0.4, shuffle=True\n",
        ")\n",
        "valX, testX, valY, testY = train_test_split(\n",
        "    restX, restY, test_size=0.5, shuffle=True\n",
        ")\n",
        "\n",
        "trainX_t = torch.tensor(trainX, dtype=torch.float32).to(device)\n",
        "trainY_t = torch.tensor(trainY, dtype=torch.float32).to(device)\n",
        "valX_t   = torch.tensor(valX, dtype=torch.float32).to(device)\n",
        "valY_t   = torch.tensor(valY, dtype=torch.float32).to(device)\n",
        "\n",
        "testX_t = torch.tensor(testX, dtype=torch.float32).to(device)\n",
        "testY_t = torch.tensor(testY, dtype=torch.float32).to(device)\n",
        "\n",
        "print(f\"Train Samples: {len(trainX)}\")\n",
        "print(f\"Val Samples:   {len(valX)}\")\n",
        "print(f\"Test Samples:  {len(testX)}\")\n",
        "\n",
        "# ----------------------------\n",
        "# Train model\n",
        "# ----------------------------\n",
        "model = LSTMModel(input_dim=5, hidden_dim=64, layer_dim=10, output_dim=1).to(device)\n",
        "trained_model = train_model(model, trainX_t, trainY_t, valX_t, valY_t, epochs=200, lr=0.01)\n",
        "\n",
        "# ----------------------------\n",
        "# Test Evaluation\n",
        "# ----------------------------\n",
        "trained_model.eval()\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits,attn = trained_model(testX_t)\n",
        "    preds = torch.sigmoid(logits)\n",
        "    pred_classes = preds.round()\n",
        "\n",
        "    test_loss = nn.BCEWithLogitsLoss()(logits, testY_t).item()\n",
        "    test_acc = (pred_classes == testY_t).float().mean().item()\n",
        "\n",
        "print(\"\\n===== TEST RESULTS =====\")\n",
        "print(f\"Test Loss: {test_loss:.5f}\")\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
        "print(\"========================\\n\")\n"
      ],
      "metadata": {
        "id": "18Jv9FnjzyU7",
        "outputId": "da99d2fc-eedb-4cae-93c8-c9aa2cc4690f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your CoinMarketCap API key: a76bd6fc-2b66-4a25-843f-321def3437bd\n",
            "Loaded 10 coins.\n",
            "Fetching historical data (or loading cached files)...\n",
            "[INFO] Using cached data for 1\n",
            "[INFO] Using cached data for 1027\n",
            "[INFO] Using cached data for 825\n",
            "[INFO] Using cached data for 52\n",
            "[INFO] Using cached data for 1839\n",
            "[INFO] Using cached data for 5426\n",
            "[INFO] Using cached data for 3408\n",
            "[INFO] Using cached data for 1958\n",
            "[INFO] Using cached data for 74\n",
            "[INFO] Using cached data for 2010\n",
            "\n",
            "✅ Fetched or loaded data for 10 coins.\n",
            "Train Samples: 288\n",
            "Val Samples:   96\n",
            "Test Samples:  96\n",
            "Epoch [1/200] | Train Loss: 0.68529 | Train Acc: 59.03% | Val Loss: 0.72817 | Val Acc: 54.17%\n",
            "Epoch [2/200] | Train Loss: 0.69228 | Train Acc: 59.03% | Val Loss: 0.69035 | Val Acc: 54.17%\n",
            "Epoch [3/200] | Train Loss: 0.67873 | Train Acc: 59.03% | Val Loss: 0.69020 | Val Acc: 54.17%\n",
            "Epoch [4/200] | Train Loss: 0.67891 | Train Acc: 59.03% | Val Loss: 0.69517 | Val Acc: 54.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3728742247.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  trainX_t = torch.tensor(trainX, dtype=torch.float32).to(device)\n",
            "/tmp/ipython-input-3728742247.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  trainY_t = torch.tensor(trainY, dtype=torch.float32).to(device)\n",
            "/tmp/ipython-input-3728742247.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  valX_t   = torch.tensor(valX, dtype=torch.float32).to(device)\n",
            "/tmp/ipython-input-3728742247.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  valY_t   = torch.tensor(valY, dtype=torch.float32).to(device)\n",
            "/tmp/ipython-input-3728742247.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  testX_t = torch.tensor(testX, dtype=torch.float32).to(device)\n",
            "/tmp/ipython-input-3728742247.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  testY_t = torch.tensor(testY, dtype=torch.float32).to(device)\n",
            "/tmp/ipython-input-2952578547.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  trainX = torch.tensor(trainX, dtype=torch.float32)\n",
            "/tmp/ipython-input-2952578547.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  trainY = torch.tensor(trainY, dtype=torch.float32)\n",
            "/tmp/ipython-input-2952578547.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  valX   = torch.tensor(valX,   dtype=torch.float32)\n",
            "/tmp/ipython-input-2952578547.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  valY   = torch.tensor(valY,   dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/200] | Train Loss: 0.67659 | Train Acc: 59.03% | Val Loss: 0.69901 | Val Acc: 54.17%\n",
            "Epoch [6/200] | Train Loss: 0.67729 | Train Acc: 59.03% | Val Loss: 0.68971 | Val Acc: 54.17%\n",
            "Epoch [7/200] | Train Loss: 0.67932 | Train Acc: 59.03% | Val Loss: 0.69113 | Val Acc: 54.17%\n",
            "Epoch [8/200] | Train Loss: 0.67766 | Train Acc: 59.03% | Val Loss: 0.69547 | Val Acc: 54.17%\n",
            "Epoch [9/200] | Train Loss: 0.67688 | Train Acc: 59.03% | Val Loss: 0.69546 | Val Acc: 54.17%\n",
            "Epoch [10/200] | Train Loss: 0.67688 | Train Acc: 59.03% | Val Loss: 0.69317 | Val Acc: 54.17%\n",
            "Epoch [11/200] | Train Loss: 0.67680 | Train Acc: 59.03% | Val Loss: 0.69418 | Val Acc: 54.17%\n",
            "Epoch [12/200] | Train Loss: 0.67669 | Train Acc: 59.03% | Val Loss: 0.69533 | Val Acc: 54.17%\n",
            "Epoch [13/200] | Train Loss: 0.67693 | Train Acc: 59.03% | Val Loss: 0.69464 | Val Acc: 54.17%\n",
            "Epoch [14/200] | Train Loss: 0.67671 | Train Acc: 59.03% | Val Loss: 0.69395 | Val Acc: 54.17%\n",
            "Epoch [15/200] | Train Loss: 0.67697 | Train Acc: 59.03% | Val Loss: 0.69450 | Val Acc: 54.17%\n",
            "Epoch [16/200] | Train Loss: 0.67677 | Train Acc: 59.03% | Val Loss: 0.69519 | Val Acc: 54.17%\n",
            "Epoch [17/200] | Train Loss: 0.67682 | Train Acc: 59.03% | Val Loss: 0.69476 | Val Acc: 54.17%\n",
            "Epoch [18/200] | Train Loss: 0.67675 | Train Acc: 59.03% | Val Loss: 0.69463 | Val Acc: 54.17%\n",
            "Epoch [19/200] | Train Loss: 0.67668 | Train Acc: 59.03% | Val Loss: 0.69453 | Val Acc: 54.17%\n",
            "Epoch [20/200] | Train Loss: 0.67693 | Train Acc: 59.03% | Val Loss: 0.69441 | Val Acc: 54.17%\n",
            "Epoch [21/200] | Train Loss: 0.67674 | Train Acc: 59.03% | Val Loss: 0.69434 | Val Acc: 54.17%\n",
            "Epoch [22/200] | Train Loss: 0.67667 | Train Acc: 59.03% | Val Loss: 0.69428 | Val Acc: 54.17%\n",
            "\n",
            "===== TEST RESULTS =====\n",
            "Test Loss: 0.69801\n",
            "Test Accuracy: 53.12%\n",
            "========================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}